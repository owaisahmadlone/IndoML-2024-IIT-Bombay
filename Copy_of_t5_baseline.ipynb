{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdF05fVYqL2M"
      },
      "source": [
        "## Importing Libraries and Modules\n",
        "\n",
        "In this cell, we import the necessary libraries and modules required for the task:\n",
        "\n",
        "- **pandas**: For data manipulation and analysis.\n",
        "- **transformers**: Includes the `T5Tokenizer` and `T5ForConditionalGeneration` classes for tokenizing text and generating predictions using the T5 model.\n",
        "- **datasets**: Provides the `Dataset` and `DatasetDict` classes for handling datasets.\n",
        "- **numpy**: For numerical operations.\n",
        "\n",
        "These libraries and modules will be used for data processing, model training, and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hom0w81Cr-t3",
        "outputId": "4f35f034-3dfd-4844-e461-9e6b8bb2eed4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q6JC7hI_qL2O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, TrainerCallback\n",
        "from datasets import Dataset, DatasetDict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Rbs11sqL2P"
      },
      "source": [
        "## Reading Data from JSONL Files\n",
        "\n",
        "In this cell, we define a function `read_jsonl` to read data from JSON Lines (JSONL) files into pandas DataFrames. We then use this function to read the following datasets:\n",
        "\n",
        "- **Training Data**: `attrebute_train.data` and `attrebute_train.solution`, with the first 1000 rows.\n",
        "- **Testing Data**: `attrebute_test.data` and `attrebute_test.solution`, with the first 200 rows.\n",
        "- **Validation Data**: `attrebute_val.data` and `attrebute_val.solution`, with the first 200 rows.\n",
        "\n",
        "The commented-out lines are for reading the entire datasets if needed. This setup allows us to work with a subset of the data for initial experimentation and testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qtK9BFmCqL2P"
      },
      "outputs": [],
      "source": [
        "def read_jsonl(file_path, nrows=None):\n",
        "    return pd.read_json(file_path, lines=True, nrows=nrows)\n",
        "\n",
        "\n",
        "train_data = read_jsonl('/content/attribute_train.data')\n",
        "train_solution = read_jsonl('/content/attribute_train.solution')\n",
        "test_df = read_jsonl('/content/attribute_test.data')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract possible labels for each category\n",
        "categories = ['L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n",
        "label_sets = {category: train_data[category].unique().tolist() for category in categories}"
      ],
      "metadata": {
        "id": "wtoEHADxvhdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "m = 100000\n",
        "val_data = train_data[:n]\n",
        "val_solution = train_solution[:n]\n",
        "\n",
        "train_data = train_data[n:n+m]\n",
        "train_solution = train_solution[n:n+m]"
      ],
      "metadata": {
        "id": "Ph__lP9AqgL2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create the test_solution DataFrame with the same columns as train_solution\n",
        "test_solution = pd.DataFrame(columns=train_solution.columns)\n",
        "\n",
        "# Step 2: Copy the 'indoml_id' column from test_data to test_solution\n",
        "test_solution['indoml_id'] = test_df['indoml_id']\n",
        "\n",
        "# Step 3: Fill all other columns with 'test'\n",
        "for column in test_solution.columns:\n",
        "    if column != 'indoml_id':\n",
        "        test_solution[column] = 'test'\n",
        "\n",
        "# Display the first few rows to verify\n",
        "test_solution.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PCvaR8XOsJft",
        "outputId": "f704c3f1-d52a-4b8b-8de1-94d3c944a1ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   indoml_id details_Brand L0_category L1_category L2_category L3_category  \\\n",
              "0          0          test        test        test        test        test   \n",
              "1          1          test        test        test        test        test   \n",
              "2          2          test        test        test        test        test   \n",
              "3          3          test        test        test        test        test   \n",
              "4          4          test        test        test        test        test   \n",
              "\n",
              "  L4_category  \n",
              "0        test  \n",
              "1        test  \n",
              "2        test  \n",
              "3        test  \n",
              "4        test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-124ad47d-3667-49fa-bae8-27f926aa2b08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>indoml_id</th>\n",
              "      <th>details_Brand</th>\n",
              "      <th>L0_category</th>\n",
              "      <th>L1_category</th>\n",
              "      <th>L2_category</th>\n",
              "      <th>L3_category</th>\n",
              "      <th>L4_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-124ad47d-3667-49fa-bae8-27f926aa2b08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-124ad47d-3667-49fa-bae8-27f926aa2b08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-124ad47d-3667-49fa-bae8-27f926aa2b08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e5b3413-df4a-4d21-bb4e-0a935a2cd32a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e5b3413-df4a-4d21-bb4e-0a935a2cd32a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e5b3413-df4a-4d21-bb4e-0a935a2cd32a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_solution",
              "summary": "{\n  \"name\": \"test_solution\",\n  \"rows\": 95036,\n  \"fields\": [\n    {\n      \"column\": \"indoml_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27434,\n        \"min\": 0,\n        \"max\": 95035,\n        \"num_unique_values\": 95036,\n        \"samples\": [\n          15236,\n          17689,\n          17961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"details_Brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L0_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L1_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L2_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L3_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L4_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ1EczHnqL2P"
      },
      "source": [
        "## Data Preprocessing and Formatting\n",
        "\n",
        "In this cell, we define a function `preprocess_data` to prepare the data for model training. This function merges the product description data with the corresponding attribute labels, then formats the data into `input_text` and `target_text` pairs:\n",
        "\n",
        "- **`input_text`**: Constructed by combining the product title, store, and manufacturer details.\n",
        "- **`target_text`**: Constructed by specifying the attribute-value pairs for brand and categories.\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "We apply the `preprocess_data` function to the training, testing, and validation datasets to generate the `input_text` and `target_text`.\n",
        "\n",
        "Finally, the processed data is converted into the Hugging Face Dataset format using `Dataset.from_pandas` for further model training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HpQjr10SqL2Q"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, solution):\n",
        "    merged = pd.merge(data, solution, on='indoml_id')\n",
        "\n",
        "    merged['input_text'] = merged.apply(lambda row: f\"title: {row['title']} store: {row['store']} details_Manufacturer: {row['details_Manufacturer']}\", axis=1)\n",
        "    merged['target_text'] = merged.apply(lambda row: f\"details_Brand: {row['details_Brand']} L0_category: {row['L0_category']} L1_category: {row['L1_category']} L2_category: {row['L2_category']} L3_category: {row['L3_category']} L4_category: {row['L4_category']}\", axis=1)\n",
        "\n",
        "    return merged[['input_text', 'target_text']]\n",
        "\n",
        "\n",
        "train_processed = preprocess_data(train_data, train_solution)\n",
        "test_processed = preprocess_data(test_df, test_solution)\n",
        "val_processed = preprocess_data(val_data, val_solution)\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_processed)\n",
        "test_dataset = Dataset.from_pandas(test_processed)\n",
        "val_dataset = Dataset.from_pandas(val_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0cSPfKVHqL2Q",
        "outputId": "1d919e50-9905-4113-dcb4-f999f2d7634c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_text': ['title: FEL-PRO HS 9188 PT-1 Head Gasket Set store: Fel-Pro details_Manufacturer: FEL-PRO',\n",
              "  'title: MAGID 15NYL KnitMaster 10 1/2 Lightweight Machine Knit Nylon Gloves, Large, White (12 Pairs) store: MAGID details_Manufacturer: MAGID',\n",
              "  'title: Eiko 55 G4-1/2 Miniature Bayonet Base Halogen Bulb, 7V/0.41 Amp store: Eiko details_Manufacturer: Eiko',\n",
              "  'title: 300 Thread Count Egyptian Cotton Sheet Set, DEEP Pocket, 300TC, Full, Solid Black store: Egyptian Cotton Factory Outlet Store details_Manufacturer: Egyptian Cotton Factory Outlet Store',\n",
              "  'title: Sunbeam Imperial Plush Heated Blanket King - Lagoon Blue store: Sunbeam details_Manufacturer: Jarden Consumer Products'],\n",
              " 'target_text': ['details_Brand: Fel-Pro L0_category: Automotive L1_category: Replacement Parts L2_category: Gaskets L3_category: Head Gasket Sets L4_category: na',\n",
              "  'details_Brand: MAGID L0_category: Tools & Home Improvement L1_category: Safety & Security L2_category: Personal Protective Equipment L3_category: Hand & Arm Protection L4_category: Lab, Safety & Work Gloves',\n",
              "  'details_Brand: Eiko L0_category: Tools & Home Improvement L1_category: Light Bulbs L2_category: Incandescent Bulbs L3_category: na L4_category: na',\n",
              "  'details_Brand: Egyptian Cotton Factory Outlet Store L0_category: Home & Kitchen L1_category: Bedding L2_category: Sheets & Pillowcases L3_category: Sheet & Pillowcase Sets L4_category: na',\n",
              "  'details_Brand: Sunbeam L0_category: Home & Kitchen L1_category: Bedding L2_category: Blankets & Throws L3_category: Bed Blankets L4_category: na']}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_dataset[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxSImd6sqL2Q"
      },
      "source": [
        "## Creating Dataset Dictionary\n",
        "\n",
        "In this cell, we create a `DatasetDict` to organize the processed datasets for training, testing, and validation. The `DatasetDict` is a convenient way to manage multiple datasets in Hugging Face's `datasets` library.\n",
        "\n",
        "- **`train`**: Contains the training dataset (`train_dataset`).\n",
        "- **`test`**: Contains the test dataset (`test_dataset`).\n",
        "- **`validation`**: Contains the validation dataset (`val_dataset`).\n",
        "\n",
        "The `DatasetDict` will be used for training and evaluating the model, allowing for easy access to different subsets of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ISKedp_GqL2Q"
      },
      "outputs": [],
      "source": [
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': test_dataset,\n",
        "    'validation': val_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEldb-RDqL2Q"
      },
      "source": [
        "## Loading the T5 Model and Tokenizer\n",
        "\n",
        "In this cell, we load the T5 model and tokenizer from the Hugging Face `transformers` library:\n",
        "\n",
        "- **`T5Tokenizer`**: Tokenizer for converting text into tokens and vice versa, using the `t5-small` pre-trained model.\n",
        "- **`T5ForConditionalGeneration`**: T5 model for sequence-to-sequence tasks, also using the `t5-small` pre-trained model.\n",
        "\n",
        "These components will be used for encoding the input text, generating predictions, and decoding the output text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DFRWf4D-qL2Q",
        "outputId": "58fb4c8d-0357-480d-df79-adf383fb1873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQYTZWyUqL2R"
      },
      "source": [
        "## Tokenizing the Dataset\n",
        "\n",
        "In this cell, we define the `preprocess_function` to tokenize the `input_text` and `target_text` using the T5 tokenizer:\n",
        "\n",
        "- **`inputs`**: Tokenized input texts with a maximum length of 352 tokens, padded and truncated as necessary.\n",
        "- **`targets`**: Tokenized target texts with a maximum length of 128 tokens, padded and truncated as necessary.\n",
        "- **`model_inputs`**: Contains the tokenized inputs and labels (target texts) for model training.\n",
        "\n",
        "The `preprocess_function` is applied to the entire dataset using the `map` method with `batched=True`, ensuring efficient processing of the data in batches.\n",
        "\n",
        "The result, `tokenized_datasets`, is a `DatasetDict` containing the tokenized versions of the train, test, and validation datasets, ready for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wUwIJIBzqL2R",
        "outputId": "632db1b4-bcb2-4294-9475-1b60243206ff",
        "colab": {
          "referenced_widgets": [
            "d20fb058068849d6a25aa2337badb43c",
            "3324a40b085e4cd8803fd35939999ef7",
            "c400590f1f2d4f1ab828ab5dd3ed004f",
            "7ab9cae441494b4293d3c71b2c3202bb",
            "2899c94ca5f84e448604274fc4d0a7c5",
            "7a8148ca3e3343b3a03d412ab930bdf6",
            "366a083d02bc49ef97cb531b8bdba882",
            "01974fd3572f4ec9923ea27a7237b75f",
            "bc5b5b8e3de742b7b0b3fc81001d94c4",
            "959858984ddb4aa9a8ef78da46f9b62e",
            "9ed7f18df1944628982f8be53dd3aa5b",
            "93042bce986c4b33986037d5bfcbf2e9",
            "7b16e72491314f58a1ddb0a6de8e081b",
            "282ccdbaef8148568d5b3622c0301f97",
            "582df6e88d9b419ab7df84bf7a688d51",
            "0a74f5be293f4281a0edb81e81b63e5c",
            "ae8833f1db0a4352b43ac4a5fd9207b4",
            "1a8a7fadd1e541c58098aee8fe15bbad",
            "e2773eedd07b4681960347e678592c4d",
            "1d3da8fa096b4391aa85fa22e5471fed",
            "1df8095e49f24c4fbcf3a31e939ea6ec",
            "566b2801f17242fea1296dc10276bf81",
            "3b2eafcf22124945898eaa754b75bb2e",
            "54f585a7c3a244eb8555663a4019f899",
            "30063e63df7348469dfc822fb47c2ce3",
            "19b51daaad2c4a73b5005a970af4250e",
            "1bfc2752a0304275a9322f80828b40c5",
            "40a3177f63cb4ef380c2c36163dbb4cc",
            "235a977084754a40ab761564cd2685b1",
            "b1d98d0124bf4d35bc42f62c07fdba02",
            "83b5096db9b94e1da2f73dbbd9a9d1ad",
            "f3d934ae5db84f808eeb38f521c9df99",
            "82a9400ac7014b8b8a27cfc497849f6b"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d20fb058068849d6a25aa2337badb43c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/95036 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93042bce986c4b33986037d5bfcbf2e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b2eafcf22124945898eaa754b75bb2e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = examples['input_text']\n",
        "    targets = examples['target_text']\n",
        "    model_inputs = tokenizer(inputs, max_length=128, padding='max_length', truncation=True)\n",
        "    labels = tokenizer(targets, max_length=128, padding='max_length', truncation=True)\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = dataset_dict.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCzmbPiXqL2R"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqAORAYXqL2R"
      },
      "outputs": [],
      "source": [
        "#tokenized_datasets.save_to_disk('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC_UuZ3_qL2R"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_from_disk\n",
        "\n",
        "# tokenized_datasets = load_from_disk('./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twekz1IxqL2R"
      },
      "source": [
        "## Configuring Training Arguments\n",
        "\n",
        "In this cell, we set up the `TrainingArguments` for training the T5 model using the Hugging Face `Trainer`:\n",
        "\n",
        "- **`output_dir`**: Directory to save the model checkpoints and results.\n",
        "- **`evaluation_strategy`**: Strategy for evaluation, set to `'epoch'`, meaning evaluation will occur at the end of each epoch.\n",
        "- **`learning_rate`**: Learning rate for optimization, set to `2e-5`.\n",
        "- **`per_device_train_batch_size`**: Batch size for training, set to `16`.\n",
        "- **`per_device_eval_batch_size`**: Batch size for evaluation, set to `16`.\n",
        "- **`num_train_epochs`**: Number of training epochs, set to `2`.\n",
        "- **`weight_decay`**: Weight decay for regularization, set to `0.01`.\n",
        "- **`save_total_limit`**: Limit on the number of checkpoints to keep, set to `3`.\n",
        "- **`logging_dir`**: Directory for logging information.\n",
        "- **`logging_steps`**: Frequency of logging, set to every 20 steps.\n",
        "- **`report_to`**: Reporting options, set to `'none'` to disable reporting.\n",
        "\n",
        "These arguments control various aspects of the training process and ensure efficient training and logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ESdlwdhjqL2R",
        "outputId": "4e30d8d2-a0fe-43cc-c68e-3064faf52d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=20,\n",
        "    report_to='none'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irgb768hqL2S"
      },
      "source": [
        "## Defining a Custom Callback for Logging\n",
        "\n",
        "In this cell, we define a custom callback class `CustomCallback` that extends `TrainerCallback` from the Hugging Face `transformers` library:\n",
        "\n",
        "- **`on_log` Method**: This method is triggered during the training process whenever logging occurs. It prints:\n",
        "  - The current training step (`state.global_step`).\n",
        "  - Each key-value pair in the `logs` dictionary.\n",
        "\n",
        "This custom callback allows for detailed logging of training progress and metrics directly to the console, providing real-time feedback during the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cMsUz20iqL2S"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            print(f\"Step: {state.global_step}\")\n",
        "            for key, value in logs.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "            print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtI25O8vqL2S"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "In this cell, we initialize and run the `Trainer` for training the T5 model:\n",
        "\n",
        "- **`model`**: The T5 model to be trained.\n",
        "- **`args`**: The `TrainingArguments` specified in the previous cell.\n",
        "- **`train_dataset`**: The tokenized training dataset.\n",
        "- **`eval_dataset`**: The tokenized validation dataset.\n",
        "- **`callbacks`**: The list of callbacks to use during training, including the custom `CustomCallback` defined earlier.\n",
        "\n",
        "After setting up the `Trainer`, we call `trainer.train()` to start the training process. The custom callback will print detailed logging information during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN-GZEvUqL2S",
        "outputId": "6bc562b9-dbe5-414e-d9f3-1b56724c4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4090' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4090/6250 1:14:51 < 39:33, 0.91 it/s, Epoch 0.65/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 20\n",
            "loss: 1.2328\n",
            "grad_norm: 0.3010375201702118\n",
            "learning_rate: 0.0019936\n",
            "epoch: 0.0032\n",
            "\n",
            "\n",
            "Step: 40\n",
            "loss: 0.2749\n",
            "grad_norm: 0.26716718077659607\n",
            "learning_rate: 0.0019872\n",
            "epoch: 0.0064\n",
            "\n",
            "\n",
            "Step: 60\n",
            "loss: 0.24\n",
            "grad_norm: 0.2254064828157425\n",
            "learning_rate: 0.0019808\n",
            "epoch: 0.0096\n",
            "\n",
            "\n",
            "Step: 80\n",
            "loss: 0.1916\n",
            "grad_norm: 0.23095083236694336\n",
            "learning_rate: 0.0019744\n",
            "epoch: 0.0128\n",
            "\n",
            "\n",
            "Step: 100\n",
            "loss: 0.1824\n",
            "grad_norm: 0.17696872353553772\n",
            "learning_rate: 0.001968\n",
            "epoch: 0.016\n",
            "\n",
            "\n",
            "Step: 120\n",
            "loss: 0.1565\n",
            "grad_norm: 0.17030836641788483\n",
            "learning_rate: 0.0019616\n",
            "epoch: 0.0192\n",
            "\n",
            "\n",
            "Step: 140\n",
            "loss: 0.1415\n",
            "grad_norm: 0.16717420518398285\n",
            "learning_rate: 0.0019552000000000003\n",
            "epoch: 0.0224\n",
            "\n",
            "\n",
            "Step: 160\n",
            "loss: 0.1329\n",
            "grad_norm: 0.1367701292037964\n",
            "learning_rate: 0.0019488\n",
            "epoch: 0.0256\n",
            "\n",
            "\n",
            "Step: 180\n",
            "loss: 0.1552\n",
            "grad_norm: 0.17059433460235596\n",
            "learning_rate: 0.0019424\n",
            "epoch: 0.0288\n",
            "\n",
            "\n",
            "Step: 200\n",
            "loss: 0.1193\n",
            "grad_norm: 0.19284522533416748\n",
            "learning_rate: 0.001936\n",
            "epoch: 0.032\n",
            "\n",
            "\n",
            "Step: 220\n",
            "loss: 0.1181\n",
            "grad_norm: 0.15224096179008484\n",
            "learning_rate: 0.0019296\n",
            "epoch: 0.0352\n",
            "\n",
            "\n",
            "Step: 240\n",
            "loss: 0.1134\n",
            "grad_norm: 0.11777956783771515\n",
            "learning_rate: 0.0019232000000000001\n",
            "epoch: 0.0384\n",
            "\n",
            "\n",
            "Step: 260\n",
            "loss: 0.1108\n",
            "grad_norm: 0.16658373177051544\n",
            "learning_rate: 0.0019168000000000002\n",
            "epoch: 0.0416\n",
            "\n",
            "\n",
            "Step: 280\n",
            "loss: 0.1039\n",
            "grad_norm: 0.13821618258953094\n",
            "learning_rate: 0.0019104\n",
            "epoch: 0.0448\n",
            "\n",
            "\n",
            "Step: 300\n",
            "loss: 0.0988\n",
            "grad_norm: 0.10347720235586166\n",
            "learning_rate: 0.0019039999999999999\n",
            "epoch: 0.048\n",
            "\n",
            "\n",
            "Step: 320\n",
            "loss: 0.0932\n",
            "grad_norm: 0.15905119478702545\n",
            "learning_rate: 0.0018976\n",
            "epoch: 0.0512\n",
            "\n",
            "\n",
            "Step: 340\n",
            "loss: 0.0938\n",
            "grad_norm: 0.16862735152244568\n",
            "learning_rate: 0.0018912\n",
            "epoch: 0.0544\n",
            "\n",
            "\n",
            "Step: 360\n",
            "loss: 0.0847\n",
            "grad_norm: 0.10818792879581451\n",
            "learning_rate: 0.0018848\n",
            "epoch: 0.0576\n",
            "\n",
            "\n",
            "Step: 380\n",
            "loss: 0.0873\n",
            "grad_norm: 0.1285276859998703\n",
            "learning_rate: 0.0018784000000000001\n",
            "epoch: 0.0608\n",
            "\n",
            "\n",
            "Step: 400\n",
            "loss: 0.0747\n",
            "grad_norm: 0.1200198233127594\n",
            "learning_rate: 0.0018720000000000002\n",
            "epoch: 0.064\n",
            "\n",
            "\n",
            "Step: 420\n",
            "loss: 0.0813\n",
            "grad_norm: 0.15667293965816498\n",
            "learning_rate: 0.0018656\n",
            "epoch: 0.0672\n",
            "\n",
            "\n",
            "Step: 440\n",
            "loss: 0.075\n",
            "grad_norm: 0.13682959973812103\n",
            "learning_rate: 0.0018592\n",
            "epoch: 0.0704\n",
            "\n",
            "\n",
            "Step: 460\n",
            "loss: 0.0667\n",
            "grad_norm: 0.09593809396028519\n",
            "learning_rate: 0.0018528\n",
            "epoch: 0.0736\n",
            "\n",
            "\n",
            "Step: 480\n",
            "loss: 0.0624\n",
            "grad_norm: 0.11589420586824417\n",
            "learning_rate: 0.0018464\n",
            "epoch: 0.0768\n",
            "\n",
            "\n",
            "Step: 500\n",
            "loss: 0.0749\n",
            "grad_norm: 0.213995561003685\n",
            "learning_rate: 0.00184\n",
            "epoch: 0.08\n",
            "\n",
            "\n",
            "Step: 520\n",
            "loss: 0.076\n",
            "grad_norm: 0.14361771941184998\n",
            "learning_rate: 0.0018336\n",
            "epoch: 0.0832\n",
            "\n",
            "\n",
            "Step: 540\n",
            "loss: 0.0759\n",
            "grad_norm: 0.13445627689361572\n",
            "learning_rate: 0.0018272\n",
            "epoch: 0.0864\n",
            "\n",
            "\n",
            "Step: 560\n",
            "loss: 0.0777\n",
            "grad_norm: 0.13203617930412292\n",
            "learning_rate: 0.0018208\n",
            "epoch: 0.0896\n",
            "\n",
            "\n",
            "Step: 580\n",
            "loss: 0.0642\n",
            "grad_norm: 0.22819526493549347\n",
            "learning_rate: 0.0018144\n",
            "epoch: 0.0928\n",
            "\n",
            "\n",
            "Step: 600\n",
            "loss: 0.0615\n",
            "grad_norm: 0.10012952238321304\n",
            "learning_rate: 0.0018080000000000001\n",
            "epoch: 0.096\n",
            "\n",
            "\n",
            "Step: 620\n",
            "loss: 0.07\n",
            "grad_norm: 0.08156884461641312\n",
            "learning_rate: 0.0018016000000000002\n",
            "epoch: 0.0992\n",
            "\n",
            "\n",
            "Step: 640\n",
            "loss: 0.0669\n",
            "grad_norm: 0.07742615044116974\n",
            "learning_rate: 0.0017952\n",
            "epoch: 0.1024\n",
            "\n",
            "\n",
            "Step: 660\n",
            "loss: 0.0616\n",
            "grad_norm: 0.13476580381393433\n",
            "learning_rate: 0.0017888\n",
            "epoch: 0.1056\n",
            "\n",
            "\n",
            "Step: 680\n",
            "loss: 0.0719\n",
            "grad_norm: 0.11295107752084732\n",
            "learning_rate: 0.0017824\n",
            "epoch: 0.1088\n",
            "\n",
            "\n",
            "Step: 700\n",
            "loss: 0.0629\n",
            "grad_norm: 0.09655038267374039\n",
            "learning_rate: 0.001776\n",
            "epoch: 0.112\n",
            "\n",
            "\n",
            "Step: 720\n",
            "loss: 0.0636\n",
            "grad_norm: 0.0837063118815422\n",
            "learning_rate: 0.0017696\n",
            "epoch: 0.1152\n",
            "\n",
            "\n",
            "Step: 740\n",
            "loss: 0.0629\n",
            "grad_norm: 0.08615308254957199\n",
            "learning_rate: 0.0017632000000000001\n",
            "epoch: 0.1184\n",
            "\n",
            "\n",
            "Step: 760\n",
            "loss: 0.0513\n",
            "grad_norm: 0.0990683063864708\n",
            "learning_rate: 0.0017568\n",
            "epoch: 0.1216\n",
            "\n",
            "\n",
            "Step: 780\n",
            "loss: 0.052\n",
            "grad_norm: 0.09404013305902481\n",
            "learning_rate: 0.0017504\n",
            "epoch: 0.1248\n",
            "\n",
            "\n",
            "Step: 800\n",
            "loss: 0.0557\n",
            "grad_norm: 0.1128910630941391\n",
            "learning_rate: 0.001744\n",
            "epoch: 0.128\n",
            "\n",
            "\n",
            "Step: 820\n",
            "loss: 0.0545\n",
            "grad_norm: 0.07594248652458191\n",
            "learning_rate: 0.0017376000000000002\n",
            "epoch: 0.1312\n",
            "\n",
            "\n",
            "Step: 840\n",
            "loss: 0.0479\n",
            "grad_norm: 0.08275297284126282\n",
            "learning_rate: 0.0017312\n",
            "epoch: 0.1344\n",
            "\n",
            "\n",
            "Step: 860\n",
            "loss: 0.0524\n",
            "grad_norm: 0.11213529855012894\n",
            "learning_rate: 0.0017248\n",
            "epoch: 0.1376\n",
            "\n",
            "\n",
            "Step: 880\n",
            "loss: 0.0473\n",
            "grad_norm: 0.09603137522935867\n",
            "learning_rate: 0.0017184\n",
            "epoch: 0.1408\n",
            "\n",
            "\n",
            "Step: 900\n",
            "loss: 0.0538\n",
            "grad_norm: 0.12343426793813705\n",
            "learning_rate: 0.001712\n",
            "epoch: 0.144\n",
            "\n",
            "\n",
            "Step: 920\n",
            "loss: 0.0411\n",
            "grad_norm: 0.08141788095235825\n",
            "learning_rate: 0.0017056\n",
            "epoch: 0.1472\n",
            "\n",
            "\n",
            "Step: 940\n",
            "loss: 0.0496\n",
            "grad_norm: 0.06712611019611359\n",
            "learning_rate: 0.0016992\n",
            "epoch: 0.1504\n",
            "\n",
            "\n",
            "Step: 960\n",
            "loss: 0.0489\n",
            "grad_norm: 0.12303201109170914\n",
            "learning_rate: 0.0016928000000000002\n",
            "epoch: 0.1536\n",
            "\n",
            "\n",
            "Step: 980\n",
            "loss: 0.0444\n",
            "grad_norm: 0.09568869322538376\n",
            "learning_rate: 0.0016864\n",
            "epoch: 0.1568\n",
            "\n",
            "\n",
            "Step: 1000\n",
            "loss: 0.046\n",
            "grad_norm: 0.0920935645699501\n",
            "learning_rate: 0.00168\n",
            "epoch: 0.16\n",
            "\n",
            "\n",
            "Step: 1020\n",
            "loss: 0.0496\n",
            "grad_norm: 0.10489308834075928\n",
            "learning_rate: 0.0016736\n",
            "epoch: 0.1632\n",
            "\n",
            "\n",
            "Step: 1040\n",
            "loss: 0.0526\n",
            "grad_norm: 0.11343812197446823\n",
            "learning_rate: 0.0016672\n",
            "epoch: 0.1664\n",
            "\n",
            "\n",
            "Step: 1060\n",
            "loss: 0.0543\n",
            "grad_norm: 0.10076499730348587\n",
            "learning_rate: 0.0016608\n",
            "epoch: 0.1696\n",
            "\n",
            "\n",
            "Step: 1080\n",
            "loss: 0.0485\n",
            "grad_norm: 0.09457378089427948\n",
            "learning_rate: 0.0016544\n",
            "epoch: 0.1728\n",
            "\n",
            "\n",
            "Step: 1100\n",
            "loss: 0.0483\n",
            "grad_norm: 0.13136360049247742\n",
            "learning_rate: 0.001648\n",
            "epoch: 0.176\n",
            "\n",
            "\n",
            "Step: 1120\n",
            "loss: 0.0546\n",
            "grad_norm: 0.08351790904998779\n",
            "learning_rate: 0.0016416\n",
            "epoch: 0.1792\n",
            "\n",
            "\n",
            "Step: 1140\n",
            "loss: 0.046\n",
            "grad_norm: 0.08817651867866516\n",
            "learning_rate: 0.0016352\n",
            "epoch: 0.1824\n",
            "\n",
            "\n",
            "Step: 1160\n",
            "loss: 0.047\n",
            "grad_norm: 0.08151870965957642\n",
            "learning_rate: 0.0016288000000000001\n",
            "epoch: 0.1856\n",
            "\n",
            "\n",
            "Step: 1180\n",
            "loss: 0.0368\n",
            "grad_norm: 0.07191571593284607\n",
            "learning_rate: 0.0016224000000000002\n",
            "epoch: 0.1888\n",
            "\n",
            "\n",
            "Step: 1200\n",
            "loss: 0.0436\n",
            "grad_norm: 0.08817221969366074\n",
            "learning_rate: 0.001616\n",
            "epoch: 0.192\n",
            "\n",
            "\n",
            "Step: 1220\n",
            "loss: 0.0408\n",
            "grad_norm: 0.06909913569688797\n",
            "learning_rate: 0.0016095999999999999\n",
            "epoch: 0.1952\n",
            "\n",
            "\n",
            "Step: 1240\n",
            "loss: 0.0414\n",
            "grad_norm: 0.07808519154787064\n",
            "learning_rate: 0.0016032\n",
            "epoch: 0.1984\n",
            "\n",
            "\n",
            "Step: 1260\n",
            "loss: 0.0442\n",
            "grad_norm: 0.09962742775678635\n",
            "learning_rate: 0.0015968\n",
            "epoch: 0.2016\n",
            "\n",
            "\n",
            "Step: 1280\n",
            "loss: 0.0424\n",
            "grad_norm: 0.1029324010014534\n",
            "learning_rate: 0.0015904\n",
            "epoch: 0.2048\n",
            "\n",
            "\n",
            "Step: 1300\n",
            "loss: 0.04\n",
            "grad_norm: 0.06241431459784508\n",
            "learning_rate: 0.0015840000000000001\n",
            "epoch: 0.208\n",
            "\n",
            "\n",
            "Step: 1320\n",
            "loss: 0.0374\n",
            "grad_norm: 0.058677129447460175\n",
            "learning_rate: 0.0015776\n",
            "epoch: 0.2112\n",
            "\n",
            "\n",
            "Step: 1340\n",
            "loss: 0.0333\n",
            "grad_norm: 0.06351509690284729\n",
            "learning_rate: 0.0015712\n",
            "epoch: 0.2144\n",
            "\n",
            "\n",
            "Step: 1360\n",
            "loss: 0.0331\n",
            "grad_norm: 0.06103833392262459\n",
            "learning_rate: 0.0015648\n",
            "epoch: 0.2176\n",
            "\n",
            "\n",
            "Step: 1380\n",
            "loss: 0.0382\n",
            "grad_norm: 0.1281038522720337\n",
            "learning_rate: 0.0015584\n",
            "epoch: 0.2208\n",
            "\n",
            "\n",
            "Step: 1400\n",
            "loss: 0.0412\n",
            "grad_norm: 0.06854984909296036\n",
            "learning_rate: 0.001552\n",
            "epoch: 0.224\n",
            "\n",
            "\n",
            "Step: 1420\n",
            "loss: 0.0432\n",
            "grad_norm: 0.05450402572751045\n",
            "learning_rate: 0.0015456\n",
            "epoch: 0.2272\n",
            "\n",
            "\n",
            "Step: 1440\n",
            "loss: 0.0423\n",
            "grad_norm: 0.08196040242910385\n",
            "learning_rate: 0.0015392\n",
            "epoch: 0.2304\n",
            "\n",
            "\n",
            "Step: 1460\n",
            "loss: 0.0388\n",
            "grad_norm: 0.07705111056566238\n",
            "learning_rate: 0.0015328\n",
            "epoch: 0.2336\n",
            "\n",
            "\n",
            "Step: 1480\n",
            "loss: 0.0369\n",
            "grad_norm: 0.0816960409283638\n",
            "learning_rate: 0.0015264\n",
            "epoch: 0.2368\n",
            "\n",
            "\n",
            "Step: 1500\n",
            "loss: 0.0331\n",
            "grad_norm: 0.07368931174278259\n",
            "learning_rate: 0.00152\n",
            "epoch: 0.24\n",
            "\n",
            "\n",
            "Step: 1520\n",
            "loss: 0.0399\n",
            "grad_norm: 0.06341055035591125\n",
            "learning_rate: 0.0015136000000000001\n",
            "epoch: 0.2432\n",
            "\n",
            "\n",
            "Step: 1540\n",
            "loss: 0.0346\n",
            "grad_norm: 0.1054721400141716\n",
            "learning_rate: 0.0015072000000000002\n",
            "epoch: 0.2464\n",
            "\n",
            "\n",
            "Step: 1560\n",
            "loss: 0.0398\n",
            "grad_norm: 0.07721666246652603\n",
            "learning_rate: 0.0015008\n",
            "epoch: 0.2496\n",
            "\n",
            "\n",
            "Step: 1580\n",
            "loss: 0.0403\n",
            "grad_norm: 0.07389020174741745\n",
            "learning_rate: 0.0014944\n",
            "epoch: 0.2528\n",
            "\n",
            "\n",
            "Step: 1600\n",
            "loss: 0.0349\n",
            "grad_norm: 0.08823112398386002\n",
            "learning_rate: 0.001488\n",
            "epoch: 0.256\n",
            "\n",
            "\n",
            "Step: 1620\n",
            "loss: 0.0358\n",
            "grad_norm: 0.07425051182508469\n",
            "learning_rate: 0.0014816\n",
            "epoch: 0.2592\n",
            "\n",
            "\n",
            "Step: 1640\n",
            "loss: 0.0329\n",
            "grad_norm: 0.07155275344848633\n",
            "learning_rate: 0.0014752\n",
            "epoch: 0.2624\n",
            "\n",
            "\n",
            "Step: 1660\n",
            "loss: 0.0359\n",
            "grad_norm: 0.07614696025848389\n",
            "learning_rate: 0.0014688000000000001\n",
            "epoch: 0.2656\n",
            "\n",
            "\n",
            "Step: 1680\n",
            "loss: 0.0371\n",
            "grad_norm: 0.07819022238254547\n",
            "learning_rate: 0.0014624\n",
            "epoch: 0.2688\n",
            "\n",
            "\n",
            "Step: 1700\n",
            "loss: 0.0422\n",
            "grad_norm: 0.08542084693908691\n",
            "learning_rate: 0.001456\n",
            "epoch: 0.272\n",
            "\n",
            "\n",
            "Step: 1720\n",
            "loss: 0.0369\n",
            "grad_norm: 0.09988769143819809\n",
            "learning_rate: 0.0014496\n",
            "epoch: 0.2752\n",
            "\n",
            "\n",
            "Step: 1740\n",
            "loss: 0.0326\n",
            "grad_norm: 0.1219632551074028\n",
            "learning_rate: 0.0014432000000000002\n",
            "epoch: 0.2784\n",
            "\n",
            "\n",
            "Step: 1760\n",
            "loss: 0.0292\n",
            "grad_norm: 0.049682073295116425\n",
            "learning_rate: 0.0014368\n",
            "epoch: 0.2816\n",
            "\n",
            "\n",
            "Step: 1780\n",
            "loss: 0.0424\n",
            "grad_norm: 0.10553401708602905\n",
            "learning_rate: 0.0014303999999999999\n",
            "epoch: 0.2848\n",
            "\n",
            "\n",
            "Step: 1800\n",
            "loss: 0.0362\n",
            "grad_norm: 0.09542384743690491\n",
            "learning_rate: 0.001424\n",
            "epoch: 0.288\n",
            "\n",
            "\n",
            "Step: 1820\n",
            "loss: 0.0367\n",
            "grad_norm: 0.08239112794399261\n",
            "learning_rate: 0.0014176\n",
            "epoch: 0.2912\n",
            "\n",
            "\n",
            "Step: 1840\n",
            "loss: 0.0291\n",
            "grad_norm: 0.07561341673135757\n",
            "learning_rate: 0.0014112\n",
            "epoch: 0.2944\n",
            "\n",
            "\n",
            "Step: 1860\n",
            "loss: 0.0306\n",
            "grad_norm: 0.0969959944486618\n",
            "learning_rate: 0.0014048\n",
            "epoch: 0.2976\n",
            "\n",
            "\n",
            "Step: 1880\n",
            "loss: 0.0308\n",
            "grad_norm: 0.06864218413829803\n",
            "learning_rate: 0.0013984000000000002\n",
            "epoch: 0.3008\n",
            "\n",
            "\n",
            "Step: 1900\n",
            "loss: 0.0288\n",
            "grad_norm: 0.09241031855344772\n",
            "learning_rate: 0.001392\n",
            "epoch: 0.304\n",
            "\n",
            "\n",
            "Step: 1920\n",
            "loss: 0.0245\n",
            "grad_norm: 0.057409416884183884\n",
            "learning_rate: 0.0013856\n",
            "epoch: 0.3072\n",
            "\n",
            "\n",
            "Step: 1940\n",
            "loss: 0.0269\n",
            "grad_norm: 0.07736886292695999\n",
            "learning_rate: 0.0013792\n",
            "epoch: 0.3104\n",
            "\n",
            "\n",
            "Step: 1960\n",
            "loss: 0.0308\n",
            "grad_norm: 0.07854777574539185\n",
            "learning_rate: 0.0013728\n",
            "epoch: 0.3136\n",
            "\n",
            "\n",
            "Step: 1980\n",
            "loss: 0.0287\n",
            "grad_norm: 0.07353247702121735\n",
            "learning_rate: 0.0013664\n",
            "epoch: 0.3168\n",
            "\n",
            "\n",
            "Step: 2000\n",
            "loss: 0.0282\n",
            "grad_norm: 0.10379604250192642\n",
            "learning_rate: 0.00136\n",
            "epoch: 0.32\n",
            "\n",
            "\n",
            "Step: 2020\n",
            "loss: 0.0246\n",
            "grad_norm: 0.051927804946899414\n",
            "learning_rate: 0.0013536\n",
            "epoch: 0.3232\n",
            "\n",
            "\n",
            "Step: 2040\n",
            "loss: 0.0306\n",
            "grad_norm: 0.04873531311750412\n",
            "learning_rate: 0.0013472\n",
            "epoch: 0.3264\n",
            "\n",
            "\n",
            "Step: 2060\n",
            "loss: 0.0292\n",
            "grad_norm: 0.06287940591573715\n",
            "learning_rate: 0.0013408\n",
            "epoch: 0.3296\n",
            "\n",
            "\n",
            "Step: 2080\n",
            "loss: 0.0357\n",
            "grad_norm: 0.06816911697387695\n",
            "learning_rate: 0.0013344000000000001\n",
            "epoch: 0.3328\n",
            "\n",
            "\n",
            "Step: 2100\n",
            "loss: 0.029\n",
            "grad_norm: 0.0327993743121624\n",
            "learning_rate: 0.0013280000000000002\n",
            "epoch: 0.336\n",
            "\n",
            "\n",
            "Step: 2120\n",
            "loss: 0.0236\n",
            "grad_norm: 0.058223579078912735\n",
            "learning_rate: 0.0013216\n",
            "epoch: 0.3392\n",
            "\n",
            "\n",
            "Step: 2140\n",
            "loss: 0.0284\n",
            "grad_norm: 0.0613214485347271\n",
            "learning_rate: 0.0013151999999999999\n",
            "epoch: 0.3424\n",
            "\n",
            "\n",
            "Step: 2160\n",
            "loss: 0.0274\n",
            "grad_norm: 0.09913071990013123\n",
            "learning_rate: 0.0013088\n",
            "epoch: 0.3456\n",
            "\n",
            "\n",
            "Step: 2180\n",
            "loss: 0.0307\n",
            "grad_norm: 0.08080687373876572\n",
            "learning_rate: 0.0013024\n",
            "epoch: 0.3488\n",
            "\n",
            "\n",
            "Step: 2200\n",
            "loss: 0.0266\n",
            "grad_norm: 0.06732451170682907\n",
            "learning_rate: 0.001296\n",
            "epoch: 0.352\n",
            "\n",
            "\n",
            "Step: 2220\n",
            "loss: 0.0217\n",
            "grad_norm: 0.055813707411289215\n",
            "learning_rate: 0.0012896000000000001\n",
            "epoch: 0.3552\n",
            "\n",
            "\n",
            "Step: 2240\n",
            "loss: 0.0289\n",
            "grad_norm: 0.06442581862211227\n",
            "learning_rate: 0.0012832\n",
            "epoch: 0.3584\n",
            "\n",
            "\n",
            "Step: 2260\n",
            "loss: 0.0203\n",
            "grad_norm: 0.06898708641529083\n",
            "learning_rate: 0.0012768\n",
            "epoch: 0.3616\n",
            "\n",
            "\n",
            "Step: 2280\n",
            "loss: 0.0291\n",
            "grad_norm: 0.06983991712331772\n",
            "learning_rate: 0.0012704\n",
            "epoch: 0.3648\n",
            "\n",
            "\n",
            "Step: 2300\n",
            "loss: 0.0294\n",
            "grad_norm: 0.06219726800918579\n",
            "learning_rate: 0.001264\n",
            "epoch: 0.368\n",
            "\n",
            "\n",
            "Step: 2320\n",
            "loss: 0.0271\n",
            "grad_norm: 0.07419165968894958\n",
            "learning_rate: 0.0012576\n",
            "epoch: 0.3712\n",
            "\n",
            "\n",
            "Step: 2340\n",
            "loss: 0.0262\n",
            "grad_norm: 0.05372185632586479\n",
            "learning_rate: 0.0012512\n",
            "epoch: 0.3744\n",
            "\n",
            "\n",
            "Step: 2360\n",
            "loss: 0.027\n",
            "grad_norm: 0.06578423082828522\n",
            "learning_rate: 0.0012448\n",
            "epoch: 0.3776\n",
            "\n",
            "\n",
            "Step: 2380\n",
            "loss: 0.0296\n",
            "grad_norm: 0.04143405333161354\n",
            "learning_rate: 0.0012384\n",
            "epoch: 0.3808\n",
            "\n",
            "\n",
            "Step: 2400\n",
            "loss: 0.0267\n",
            "grad_norm: 0.09639447182416916\n",
            "learning_rate: 0.001232\n",
            "epoch: 0.384\n",
            "\n",
            "\n",
            "Step: 2420\n",
            "loss: 0.024\n",
            "grad_norm: 0.0666799247264862\n",
            "learning_rate: 0.0012256\n",
            "epoch: 0.3872\n",
            "\n",
            "\n",
            "Step: 2440\n",
            "loss: 0.0229\n",
            "grad_norm: 0.06518636643886566\n",
            "learning_rate: 0.0012192000000000001\n",
            "epoch: 0.3904\n",
            "\n",
            "\n",
            "Step: 2460\n",
            "loss: 0.0263\n",
            "grad_norm: 0.057601939886808395\n",
            "learning_rate: 0.0012128000000000002\n",
            "epoch: 0.3936\n",
            "\n",
            "\n",
            "Step: 2480\n",
            "loss: 0.0232\n",
            "grad_norm: 0.06770416349172592\n",
            "learning_rate: 0.0012063999999999998\n",
            "epoch: 0.3968\n",
            "\n",
            "\n",
            "Step: 2500\n",
            "loss: 0.0277\n",
            "grad_norm: 0.05775904282927513\n",
            "learning_rate: 0.0012\n",
            "epoch: 0.4\n",
            "\n",
            "\n",
            "Step: 2520\n",
            "loss: 0.0267\n",
            "grad_norm: 0.08500780910253525\n",
            "learning_rate: 0.0011936\n",
            "epoch: 0.4032\n",
            "\n",
            "\n",
            "Step: 2540\n",
            "loss: 0.0235\n",
            "grad_norm: 0.0801408663392067\n",
            "learning_rate: 0.0011872\n",
            "epoch: 0.4064\n",
            "\n",
            "\n",
            "Step: 2560\n",
            "loss: 0.0193\n",
            "grad_norm: 0.05812930315732956\n",
            "learning_rate: 0.0011808\n",
            "epoch: 0.4096\n",
            "\n",
            "\n",
            "Step: 2580\n",
            "loss: 0.0248\n",
            "grad_norm: 0.07432641088962555\n",
            "learning_rate: 0.0011744000000000001\n",
            "epoch: 0.4128\n",
            "\n",
            "\n",
            "Step: 2600\n",
            "loss: 0.0235\n",
            "grad_norm: 0.04734030365943909\n",
            "learning_rate: 0.001168\n",
            "epoch: 0.416\n",
            "\n",
            "\n",
            "Step: 2620\n",
            "loss: 0.0229\n",
            "grad_norm: 0.07289300113916397\n",
            "learning_rate: 0.0011616\n",
            "epoch: 0.4192\n",
            "\n",
            "\n",
            "Step: 2640\n",
            "loss: 0.0291\n",
            "grad_norm: 0.2096136510372162\n",
            "learning_rate: 0.0011552\n",
            "epoch: 0.4224\n",
            "\n",
            "\n",
            "Step: 2660\n",
            "loss: 0.0211\n",
            "grad_norm: 0.03906390070915222\n",
            "learning_rate: 0.0011488000000000002\n",
            "epoch: 0.4256\n",
            "\n",
            "\n",
            "Step: 2680\n",
            "loss: 0.0166\n",
            "grad_norm: 0.029359975829720497\n",
            "learning_rate: 0.0011424\n",
            "epoch: 0.4288\n",
            "\n",
            "\n",
            "Step: 2700\n",
            "loss: 0.021\n",
            "grad_norm: 0.11547285318374634\n",
            "learning_rate: 0.0011359999999999999\n",
            "epoch: 0.432\n",
            "\n",
            "\n",
            "Step: 2720\n",
            "loss: 0.021\n",
            "grad_norm: 0.10401707887649536\n",
            "learning_rate: 0.0011296\n",
            "epoch: 0.4352\n",
            "\n",
            "\n",
            "Step: 2740\n",
            "loss: 0.0221\n",
            "grad_norm: 0.05582520738244057\n",
            "learning_rate: 0.0011232\n",
            "epoch: 0.4384\n",
            "\n",
            "\n",
            "Step: 2760\n",
            "loss: 0.0184\n",
            "grad_norm: 0.05904112011194229\n",
            "learning_rate: 0.0011168\n",
            "epoch: 0.4416\n",
            "\n",
            "\n",
            "Step: 2780\n",
            "loss: 0.0192\n",
            "grad_norm: 0.08315826207399368\n",
            "learning_rate: 0.0011104\n",
            "epoch: 0.4448\n",
            "\n",
            "\n",
            "Step: 2800\n",
            "loss: 0.0229\n",
            "grad_norm: 0.10536438226699829\n",
            "learning_rate: 0.0011040000000000002\n",
            "epoch: 0.448\n",
            "\n",
            "\n",
            "Step: 2820\n",
            "loss: 0.0186\n",
            "grad_norm: 0.05526674538850784\n",
            "learning_rate: 0.0010976\n",
            "epoch: 0.4512\n",
            "\n",
            "\n",
            "Step: 2840\n",
            "loss: 0.0236\n",
            "grad_norm: 0.059653282165527344\n",
            "learning_rate: 0.0010912\n",
            "epoch: 0.4544\n",
            "\n",
            "\n",
            "Step: 2860\n",
            "loss: 0.019\n",
            "grad_norm: 0.032731276005506516\n",
            "learning_rate: 0.0010848\n",
            "epoch: 0.4576\n",
            "\n",
            "\n",
            "Step: 2880\n",
            "loss: 0.0219\n",
            "grad_norm: 0.0453147254884243\n",
            "learning_rate: 0.0010784\n",
            "epoch: 0.4608\n",
            "\n",
            "\n",
            "Step: 2900\n",
            "loss: 0.0213\n",
            "grad_norm: 0.08116664737462997\n",
            "learning_rate: 0.001072\n",
            "epoch: 0.464\n",
            "\n",
            "\n",
            "Step: 2920\n",
            "loss: 0.0188\n",
            "grad_norm: 0.05943521484732628\n",
            "learning_rate: 0.0010656\n",
            "epoch: 0.4672\n",
            "\n",
            "\n",
            "Step: 2940\n",
            "loss: 0.0219\n",
            "grad_norm: 0.05281883105635643\n",
            "learning_rate: 0.0010592\n",
            "epoch: 0.4704\n",
            "\n",
            "\n",
            "Step: 2960\n",
            "loss: 0.0251\n",
            "grad_norm: 0.0609629862010479\n",
            "learning_rate: 0.0010528\n",
            "epoch: 0.4736\n",
            "\n",
            "\n",
            "Step: 2980\n",
            "loss: 0.0222\n",
            "grad_norm: 0.06521313637495041\n",
            "learning_rate: 0.0010464\n",
            "epoch: 0.4768\n",
            "\n",
            "\n",
            "Step: 3000\n",
            "loss: 0.0211\n",
            "grad_norm: 0.04537597671151161\n",
            "learning_rate: 0.0010400000000000001\n",
            "epoch: 0.48\n",
            "\n",
            "\n",
            "Step: 3020\n",
            "loss: 0.0205\n",
            "grad_norm: 0.05406330153346062\n",
            "learning_rate: 0.0010336000000000002\n",
            "epoch: 0.4832\n",
            "\n",
            "\n",
            "Step: 3040\n",
            "loss: 0.0177\n",
            "grad_norm: 0.06995285302400589\n",
            "learning_rate: 0.0010271999999999998\n",
            "epoch: 0.4864\n",
            "\n",
            "\n",
            "Step: 3060\n",
            "loss: 0.0199\n",
            "grad_norm: 0.0691191554069519\n",
            "learning_rate: 0.0010207999999999999\n",
            "epoch: 0.4896\n",
            "\n",
            "\n",
            "Step: 3080\n",
            "loss: 0.0254\n",
            "grad_norm: 0.0897589772939682\n",
            "learning_rate: 0.0010144\n",
            "epoch: 0.4928\n",
            "\n",
            "\n",
            "Step: 3100\n",
            "loss: 0.0236\n",
            "grad_norm: 0.07068223506212234\n",
            "learning_rate: 0.001008\n",
            "epoch: 0.496\n",
            "\n",
            "\n",
            "Step: 3120\n",
            "loss: 0.0238\n",
            "grad_norm: 0.07267969846725464\n",
            "learning_rate: 0.0010016\n",
            "epoch: 0.4992\n",
            "\n",
            "\n",
            "Step: 3140\n",
            "loss: 0.0167\n",
            "grad_norm: 0.07986269146203995\n",
            "learning_rate: 0.0009952\n",
            "epoch: 0.5024\n",
            "\n",
            "\n",
            "Step: 3160\n",
            "loss: 0.0212\n",
            "grad_norm: 0.1122308149933815\n",
            "learning_rate: 0.0009888\n",
            "epoch: 0.5056\n",
            "\n",
            "\n",
            "Step: 3180\n",
            "loss: 0.0191\n",
            "grad_norm: 0.04228552430868149\n",
            "learning_rate: 0.0009824\n",
            "epoch: 0.5088\n",
            "\n",
            "\n",
            "Step: 3200\n",
            "loss: 0.0189\n",
            "grad_norm: 0.053281623870134354\n",
            "learning_rate: 0.000976\n",
            "epoch: 0.512\n",
            "\n",
            "\n",
            "Step: 3220\n",
            "loss: 0.023\n",
            "grad_norm: 0.055176153779029846\n",
            "learning_rate: 0.0009696\n",
            "epoch: 0.5152\n",
            "\n",
            "\n",
            "Step: 3240\n",
            "loss: 0.0176\n",
            "grad_norm: 0.0408882237970829\n",
            "learning_rate: 0.0009632\n",
            "epoch: 0.5184\n",
            "\n",
            "\n",
            "Step: 3260\n",
            "loss: 0.0223\n",
            "grad_norm: 0.06947677582502365\n",
            "learning_rate: 0.0009568000000000001\n",
            "epoch: 0.5216\n",
            "\n",
            "\n",
            "Step: 3280\n",
            "loss: 0.0206\n",
            "grad_norm: 0.040215037763118744\n",
            "learning_rate: 0.0009504\n",
            "epoch: 0.5248\n",
            "\n",
            "\n",
            "Step: 3300\n",
            "loss: 0.0212\n",
            "grad_norm: 0.04688464105129242\n",
            "learning_rate: 0.000944\n",
            "epoch: 0.528\n",
            "\n",
            "\n",
            "Step: 3320\n",
            "loss: 0.017\n",
            "grad_norm: 0.04560382291674614\n",
            "learning_rate: 0.0009376\n",
            "epoch: 0.5312\n",
            "\n",
            "\n",
            "Step: 3340\n",
            "loss: 0.019\n",
            "grad_norm: 0.07658705860376358\n",
            "learning_rate: 0.0009312000000000001\n",
            "epoch: 0.5344\n",
            "\n",
            "\n",
            "Step: 3360\n",
            "loss: 0.018\n",
            "grad_norm: 0.037527941167354584\n",
            "learning_rate: 0.0009247999999999999\n",
            "epoch: 0.5376\n",
            "\n",
            "\n",
            "Step: 3380\n",
            "loss: 0.0198\n",
            "grad_norm: 0.09273367375135422\n",
            "learning_rate: 0.0009184\n",
            "epoch: 0.5408\n",
            "\n",
            "\n",
            "Step: 3400\n",
            "loss: 0.0209\n",
            "grad_norm: 0.045811381191015244\n",
            "learning_rate: 0.000912\n",
            "epoch: 0.544\n",
            "\n",
            "\n",
            "Step: 3420\n",
            "loss: 0.0197\n",
            "grad_norm: 0.03549260273575783\n",
            "learning_rate: 0.0009056\n",
            "epoch: 0.5472\n",
            "\n",
            "\n",
            "Step: 3440\n",
            "loss: 0.0201\n",
            "grad_norm: 0.04039330780506134\n",
            "learning_rate: 0.0008992000000000001\n",
            "epoch: 0.5504\n",
            "\n",
            "\n",
            "Step: 3460\n",
            "loss: 0.0188\n",
            "grad_norm: 0.0960393100976944\n",
            "learning_rate: 0.0008928\n",
            "epoch: 0.5536\n",
            "\n",
            "\n",
            "Step: 3480\n",
            "loss: 0.0203\n",
            "grad_norm: 0.057607412338256836\n",
            "learning_rate: 0.0008864\n",
            "epoch: 0.5568\n",
            "\n",
            "\n",
            "Step: 3500\n",
            "loss: 0.0204\n",
            "grad_norm: 0.07472709566354752\n",
            "learning_rate: 0.00088\n",
            "epoch: 0.56\n",
            "\n",
            "\n",
            "Step: 3520\n",
            "loss: 0.0169\n",
            "grad_norm: 0.04679461196064949\n",
            "learning_rate: 0.0008736000000000001\n",
            "epoch: 0.5632\n",
            "\n",
            "\n",
            "Step: 3540\n",
            "loss: 0.0173\n",
            "grad_norm: 0.05721493810415268\n",
            "learning_rate: 0.0008671999999999999\n",
            "epoch: 0.5664\n",
            "\n",
            "\n",
            "Step: 3560\n",
            "loss: 0.0154\n",
            "grad_norm: 0.026560509577393532\n",
            "learning_rate: 0.0008608\n",
            "epoch: 0.5696\n",
            "\n",
            "\n",
            "Step: 3580\n",
            "loss: 0.016\n",
            "grad_norm: 0.04663119465112686\n",
            "learning_rate: 0.0008544000000000001\n",
            "epoch: 0.5728\n",
            "\n",
            "\n",
            "Step: 3600\n",
            "loss: 0.0142\n",
            "grad_norm: 0.03145190328359604\n",
            "learning_rate: 0.000848\n",
            "epoch: 0.576\n",
            "\n",
            "\n",
            "Step: 3620\n",
            "loss: 0.0184\n",
            "grad_norm: 0.04976014420390129\n",
            "learning_rate: 0.0008416000000000001\n",
            "epoch: 0.5792\n",
            "\n",
            "\n",
            "Step: 3640\n",
            "loss: 0.0182\n",
            "grad_norm: 0.08707942813634872\n",
            "learning_rate: 0.0008352\n",
            "epoch: 0.5824\n",
            "\n",
            "\n",
            "Step: 3660\n",
            "loss: 0.0203\n",
            "grad_norm: 0.04887475073337555\n",
            "learning_rate: 0.0008288\n",
            "epoch: 0.5856\n",
            "\n",
            "\n",
            "Step: 3680\n",
            "loss: 0.0185\n",
            "grad_norm: 0.09702514111995697\n",
            "learning_rate: 0.0008224\n",
            "epoch: 0.5888\n",
            "\n",
            "\n",
            "Step: 3700\n",
            "loss: 0.021\n",
            "grad_norm: 0.0871000811457634\n",
            "learning_rate: 0.000816\n",
            "epoch: 0.592\n",
            "\n",
            "\n",
            "Step: 3720\n",
            "loss: 0.0203\n",
            "grad_norm: 0.048501864075660706\n",
            "learning_rate: 0.0008096000000000001\n",
            "epoch: 0.5952\n",
            "\n",
            "\n",
            "Step: 3740\n",
            "loss: 0.0177\n",
            "grad_norm: 0.06273184716701508\n",
            "learning_rate: 0.0008032\n",
            "epoch: 0.5984\n",
            "\n",
            "\n",
            "Step: 3760\n",
            "loss: 0.0185\n",
            "grad_norm: 0.06793585419654846\n",
            "learning_rate: 0.0007968\n",
            "epoch: 0.6016\n",
            "\n",
            "\n",
            "Step: 3780\n",
            "loss: 0.0206\n",
            "grad_norm: 0.09535529464483261\n",
            "learning_rate: 0.0007904\n",
            "epoch: 0.6048\n",
            "\n",
            "\n",
            "Step: 3800\n",
            "loss: 0.0191\n",
            "grad_norm: 0.10519342869520187\n",
            "learning_rate: 0.0007840000000000001\n",
            "epoch: 0.608\n",
            "\n",
            "\n",
            "Step: 3820\n",
            "loss: 0.0152\n",
            "grad_norm: 0.05364418774843216\n",
            "learning_rate: 0.0007775999999999999\n",
            "epoch: 0.6112\n",
            "\n",
            "\n",
            "Step: 3840\n",
            "loss: 0.0164\n",
            "grad_norm: 0.0807337537407875\n",
            "learning_rate: 0.0007712\n",
            "epoch: 0.6144\n",
            "\n",
            "\n",
            "Step: 3860\n",
            "loss: 0.0179\n",
            "grad_norm: 0.06354115903377533\n",
            "learning_rate: 0.0007648\n",
            "epoch: 0.6176\n",
            "\n",
            "\n",
            "Step: 3880\n",
            "loss: 0.0169\n",
            "grad_norm: 0.08468291908502579\n",
            "learning_rate: 0.0007584\n",
            "epoch: 0.6208\n",
            "\n",
            "\n",
            "Step: 3900\n",
            "loss: 0.0178\n",
            "grad_norm: 0.02774452604353428\n",
            "learning_rate: 0.0007520000000000001\n",
            "epoch: 0.624\n",
            "\n",
            "\n",
            "Step: 3920\n",
            "loss: 0.016\n",
            "grad_norm: 0.09013247489929199\n",
            "learning_rate: 0.0007456\n",
            "epoch: 0.6272\n",
            "\n",
            "\n",
            "Step: 3940\n",
            "loss: 0.0159\n",
            "grad_norm: 0.050670888274908066\n",
            "learning_rate: 0.0007392\n",
            "epoch: 0.6304\n",
            "\n",
            "\n",
            "Step: 3960\n",
            "loss: 0.0153\n",
            "grad_norm: 0.0457516573369503\n",
            "learning_rate: 0.0007328\n",
            "epoch: 0.6336\n",
            "\n",
            "\n",
            "Step: 3980\n",
            "loss: 0.0177\n",
            "grad_norm: 0.07985514402389526\n",
            "learning_rate: 0.0007264000000000001\n",
            "epoch: 0.6368\n",
            "\n",
            "\n",
            "Step: 4000\n",
            "loss: 0.0158\n",
            "grad_norm: 0.046415891498327255\n",
            "learning_rate: 0.0007199999999999999\n",
            "epoch: 0.64\n",
            "\n",
            "\n",
            "Step: 4020\n",
            "loss: 0.0136\n",
            "grad_norm: 0.0305844284594059\n",
            "learning_rate: 0.0007136\n",
            "epoch: 0.6432\n",
            "\n",
            "\n",
            "Step: 4040\n",
            "loss: 0.0158\n",
            "grad_norm: 0.0977892354130745\n",
            "learning_rate: 0.0007072000000000001\n",
            "epoch: 0.6464\n",
            "\n",
            "\n",
            "Step: 4060\n",
            "loss: 0.013\n",
            "grad_norm: 0.08492246270179749\n",
            "learning_rate: 0.0007008\n",
            "epoch: 0.6496\n",
            "\n",
            "\n",
            "Step: 4080\n",
            "loss: 0.0162\n",
            "grad_norm: 0.06694414466619492\n",
            "learning_rate: 0.0006944000000000001\n",
            "epoch: 0.6528\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    callbacks=[CustomCallback()]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2DqzXCYqL2S"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "In this cell, we evaluate the trained model on both the validation and test datasets:\n",
        "\n",
        "- **Validation Evaluation**: We use the `trainer.evaluate()` method to assess the model's performance on the validation dataset (`tokenized_datasets['validation']`). The validation loss is printed to provide an indication of how well the model generalizes to unseen validation data.\n",
        "\n",
        "- **Test Evaluation**: Similarly, we evaluate the model on the test dataset (`tokenized_datasets['test']`). The test loss is printed to gauge the model's performance on the final test set.\n",
        "\n",
        "The `eval_loss` metric provides insight into the model's performance, helping to assess its accuracy and effectiveness on the given datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAeFLOV8qL2T",
        "outputId": "cf8b77a9-ce5b-4b48-99a3-ed8e5c6b0b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 250\n",
            "eval_loss: 0.17515872418880463\n",
            "eval_runtime: 0.8743\n",
            "eval_samples_per_second: 228.76\n",
            "eval_steps_per_second: 28.595\n",
            "epoch: 2.0\n",
            "\n",
            "\n",
            "Validation Loss: 0.17515872418880463\n",
            "Step: 250\n",
            "eval_loss: 0.16509920358657837\n",
            "eval_runtime: 0.8694\n",
            "eval_samples_per_second: 230.051\n",
            "eval_steps_per_second: 28.756\n",
            "epoch: 2.0\n",
            "\n",
            "\n",
            "Test Loss: 0.16509920358657837\n"
          ]
        }
      ],
      "source": [
        "# val_results = trainer.evaluate(eval_dataset=tokenized_datasets['validation'])\n",
        "# print(f\"Validation Loss: {val_results['eval_loss']}\")\n",
        "\n",
        "# test_results = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
        "# print(f\"Test Loss: {test_results['eval_loss']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8nNlzbmqL2T"
      },
      "source": [
        "## Saving the Fine-Tuned Model\n",
        "\n",
        "In this cell, we save the fine-tuned T5 model and tokenizer to a specified directory:\n",
        "\n",
        "- **`model.save_pretrained('./fine_tuned_t5_1000dp')`**: Saves the trained T5 model to the directory `./fine_tuned_t5`. This allows you to load the model later without retraining.\n",
        "\n",
        "- **`tokenizer.save_pretrained('./fine_tuned_t5_1000dp')`**: Saves the tokenizer associated with the T5 model to the same directory. This ensures that you can use the same tokenizer for encoding and decoding text during inference.\n",
        "\n",
        "Saving both the model and tokenizer ensures that you can resume work or deploy the model in the future with consistent results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl-fJ8eWqL2T",
        "outputId": "3cbf13cf-c47e-40b1-cb5f-c92b514b2d75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./fine_tuned_t5_1000dp/tokenizer_config.json',\n",
              " './fine_tuned_t5_1000dp/special_tokens_map.json',\n",
              " './fine_tuned_t5_1000dp/spiece.model',\n",
              " './fine_tuned_t5_1000dp/added_tokens.json')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('./fine_tuned_t5_1000dp')\n",
        "tokenizer.save_pretrained('./fine_tuned_t5_1000dp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAzzlj_XqL2T"
      },
      "source": [
        "## Loading the Fine-Tuned Model and Tokenizer\n",
        "\n",
        "In this cell, we load the fine-tuned T5 model and tokenizer from the specified directory and set up the environment for evaluation:\n",
        "\n",
        "- **`device`**: Determines whether to use a GPU (`cuda`) or CPU for computation based on availability.\n",
        "\n",
        "- **`model`**: Loads the fine-tuned T5 model and moves it to the appropriate device (`cuda` or `cpu`).\n",
        "\n",
        "- **`tokenizer`**: Loads the tokenizer associated with the fine-tuned T5 model.\n",
        "\n",
        "The model is set to evaluation mode with `model.eval()`, preparing it for generating predictions.\n",
        "\n",
        "### Functions\n",
        "\n",
        "- **`generate_text(inputs)`**: Takes a batch of input texts, tokenizes them, and generates predictions using the fine-tuned model. It returns the generated texts after decoding them from token IDs.\n",
        "\n",
        "- **`extract_details(text)`**: Extracts attribute details from the generated or target text using regular expressions. It returns the details for brand and categories, defaulting to `'na'` if not found.\n",
        "\n",
        "- **`clean_repeated_patterns(text)`**: Cleans the generated text by removing redundant patterns, specifically handling the `L4_category`.\n",
        "\n",
        "These functions will be used for generating predictions and extracting and cleaning the details from the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OkY3tqvqL2T",
        "outputId": "b0fea65a-5b94-479e-fe8a-9ae6e2cc24e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# model = T5ForConditionalGeneration.from_pretrained('./fine_tuned_t5_1000dp').to(device)\n",
        "# tokenizer = T5Tokenizer.from_pretrained('./fine_tuned_t5_1000dp')\n",
        "\n",
        "model.eval()\n",
        "\n",
        "test_data = test_dataset['input_text']\n",
        "test_labels = test_dataset['target_text']\n",
        "\n",
        "def generate_text(inputs):\n",
        "    inputs = tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=352)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=128)\n",
        "\n",
        "    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return generated_texts\n",
        "\n",
        "def extract_details(text):\n",
        "    pattern = r'details_Brand: (.*?) L0_category: (.*?) L1_category: (.*?) L2_category: (.*?) L3_category: (.*?) L4_category: (.*)'\n",
        "    match = re.match(pattern, text)\n",
        "    if match:\n",
        "        return tuple(item if item is not None else 'na' for item in match.groups())\n",
        "    return 'na', 'na', 'na', 'na', 'na', 'na'\n",
        "\n",
        "def clean_repeated_patterns(text):\n",
        "    cleaned_data = text.split(' L4_category')[0]\n",
        "    return cleaned_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyontqUDqL2U"
      },
      "source": [
        "## Generating Predictions and Extracting Details\n",
        "\n",
        "In this cell, we process the test data in batches to generate predictions and extract attribute details:\n",
        "\n",
        "- **`batch_size`**: The number of samples processed in each batch, set to `128`.\n",
        "\n",
        "- **`generated_details`**: List to store extracted details from generated texts.\n",
        "- **`target_details`**: List to store extracted details from target texts.\n",
        "\n",
        "### Processing Loop\n",
        "\n",
        "We iterate over the test data in batches:\n",
        "1. **Batch Extraction**: For each batch of inputs, we generate predictions using the `generate_text` function.\n",
        "2. **Details Extraction**: For each generated text and corresponding label, we extract and append details using the `extract_details` function.\n",
        "\n",
        "**Note**: The `batch_labels` are included here for completeness, but they are not used in this code snippet for generating predictions.\n",
        "\n",
        "Finally, a message is printed to indicate that the extraction of generated information is complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create TF-IDF vectorizer to compute cosine similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Function to find the closest label using cosine similarity\n",
        "def find_closest_label(generated_label, possible_labels):\n",
        "    possible_labels_vectorized = vectorizer.fit_transform(possible_labels)\n",
        "    generated_label_vectorized = vectorizer.transform([generated_label])\n",
        "\n",
        "    cosine_similarities = cosine_similarity(generated_label_vectorized, possible_labels_vectorized)\n",
        "    closest_label_index = cosine_similarities.argmax()\n",
        "\n",
        "    return possible_labels[closest_label_index]"
      ],
      "metadata": {
        "id": "rDUk6T0OvrsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "generated_details = []\n",
        "target_details = []\n",
        "\n",
        "for i in tqdm(range(0, len(test_data), batch_size), desc=\"Processing test data\"):\n",
        "    batch_inputs = test_data[i:i+batch_size]\n",
        "    batch_labels = test_labels[i:i+batch_size]  # Assuming `val_solution` contains the correct labels for the validation set\n",
        "\n",
        "    # Generate text using your model\n",
        "    generated_texts = generate_text(batch_inputs)\n",
        "\n",
        "    for generated_text, label in zip(generated_texts, batch_labels):\n",
        "        # Extract the details as a tuple from the generated text\n",
        "        details = extract_details(generated_text)\n",
        "\n",
        "        # Correcting the details if the generated label is not valid\n",
        "        corrected_details = []\n",
        "        for i, category in enumerate(categories):\n",
        "            generated_label = details[i]  # Extract the label corresponding to the category\n",
        "            if generated_label not in label_sets[category]:\n",
        "                closest_label = find_closest_label(generated_label, label_sets[category])\n",
        "                corrected_details.append(closest_label)\n",
        "            else:\n",
        "                corrected_details.append(generated_label)\n",
        "\n",
        "        # Append the corrected details as a tuple\n",
        "        generated_details.append(tuple(corrected_details))\n",
        "\n",
        "        # Extract the details from the actual target label and append\n",
        "        target_details.append(extract_details(label))\n",
        "\n",
        "\n",
        "print('Generated info extracted and corrected...')\n",
        "print(len(generated_details))"
      ],
      "metadata": {
        "id": "ffy60NnqzwYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "394t7LtOqL2U",
        "outputId": "a58faae4-af37-47e1-b777-721b57173967"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing test data: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated info extracted.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# batch_size = 128\n",
        "# generated_details = []\n",
        "# target_details = []\n",
        "\n",
        "# for i in tqdm(range(0, len(test_data), batch_size), desc=\"Processing test data\"):\n",
        "#     batch_inputs = test_data[i:i+batch_size]\n",
        "#     batch_labels = test_label[i:i+batch_size] #you are not going to have this\n",
        "\n",
        "#     generated_texts = generate_text(batch_inputs)\n",
        "\n",
        "#     for generated_text, label in zip(generated_texts, batch_labels):\n",
        "#         generated_details.append(extract_details(generated_text))\n",
        "#         target_details.append(extract_details(label))\n",
        "\n",
        "# print('Generated info extracted.............')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7S5venKqL2U"
      },
      "source": [
        "## Evaluating Model Performance by Category\n",
        "\n",
        "In this cell, we evaluate the model's performance by splitting the generated and target details into categories and calculating various metrics:\n",
        "\n",
        "### Data Preparation\n",
        "\n",
        "- **`generated_dict`** and **`target_dict`**: Dictionaries to store generated and target details for each category (0 through 5). The `generated_details` and `target_details` lists are split into these dictionaries based on category indices.\n",
        "\n",
        "- **Cleaning Repeated Patterns**: The `L4_category` entries in `generated_dict` are cleaned using the `clean_repeated_patterns` function to remove redundant patterns.\n",
        "\n",
        "### Metrics Calculation\n",
        "\n",
        "- **`categories`**: List of categories for which metrics will be computed: `details_Brand`, `L0_category`, `L1_category`, `L2_category`, `L3_category`, and `L4_category`.\n",
        "\n",
        "- **`metrics`**: List of metrics to be calculated: `accuracy`, `precision`, `recall`, and `f1`.\n",
        "\n",
        "For each category:\n",
        "1. **Compute Metrics**: Accuracy, precision, recall, and F1 score are calculated using `accuracy_score`, `precision_score`, `recall_score`, and `f1_score` from `sklearn.metrics`. Metrics are computed with macro averaging to handle multi-class classification.\n",
        "\n",
        "2. **Print Results**: The results for each category are printed, showing the calculated metrics with four decimal places.\n",
        "\n",
        "The printed results provide insight into the performance of the model across different categories and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng6kQrKgqL2U",
        "outputId": "9b3c8742-21cc-454e-e1cd-238759362b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitted into category.............\n",
            "\n",
            "Current Category:  details_Brand\n",
            "Current Category:  L0_category\n",
            "Current Category:  L1_category\n",
            "Current Category:  L2_category\n",
            "Current Category:  L3_category\n",
            "Current Category:  L4_category\n",
            "\n",
            "details_Brand:\n",
            "  accuracy: 0.9650\n",
            "  precision: 0.9267\n",
            "  recall: 0.9267\n",
            "  f1: 0.9267\n",
            "\n",
            "L0_category:\n",
            "  accuracy: 0.5750\n",
            "  precision: 0.2829\n",
            "  recall: 0.2239\n",
            "  f1: 0.2241\n",
            "\n",
            "L1_category:\n",
            "  accuracy: 0.4300\n",
            "  precision: 0.1488\n",
            "  recall: 0.1490\n",
            "  f1: 0.1340\n",
            "\n",
            "L2_category:\n",
            "  accuracy: 0.1800\n",
            "  precision: 0.0496\n",
            "  recall: 0.0462\n",
            "  f1: 0.0413\n",
            "\n",
            "L3_category:\n",
            "  accuracy: 0.1450\n",
            "  precision: 0.0846\n",
            "  recall: 0.0798\n",
            "  f1: 0.0786\n",
            "\n",
            "L4_category:\n",
            "  accuracy: 0.3850\n",
            "  precision: 0.0667\n",
            "  recall: 0.0581\n",
            "  f1: 0.0594\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_dict = {i: [] for i in range(6)}\n",
        "target_dict = {i: [] for i in range(6)}\n",
        "\n",
        "for gen, tar in zip(generated_details, target_details):\n",
        "    for i in range(6):\n",
        "        generated_dict[i].append(gen[i])\n",
        "        target_dict[i].append(tar[i])\n",
        "\n",
        "print('Splitted into category.............\\n')\n",
        "\n",
        "# Clean repeated patterns in L4_category\n",
        "generated_dict[5] = [clean_repeated_patterns(text) for text in generated_dict[5]]\n",
        "\n",
        "categories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "results = {category: {metric: 0 for metric in metrics} for category in categories}\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    print('Current Category: ', category)\n",
        "    y_true = target_dict[i]\n",
        "    y_pred = generated_dict[i]\n",
        "\n",
        "    results[category]['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    results[category]['precision'] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    results[category]['recall'] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    results[category]['f1'] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "print()\n",
        "\n",
        "for category, metrics in results.items():\n",
        "    print(f\"{category}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttoZzHNZqL2U"
      },
      "source": [
        "## Computing Item-Level Accuracy\n",
        "\n",
        "In this cell, we define a function to compute item-level accuracy, which measures how often all predicted categories match the target categories for each item:\n",
        "\n",
        "### Function: `compute_item_accuracy`\n",
        "\n",
        "- **Inputs**:\n",
        "  - `generated_details`: List of predicted details for each item.\n",
        "  - `target_details`: List of true details for each item.\n",
        "\n",
        "- **Process**:\n",
        "  - **Count Correct Items**: Iterates through pairs of generated and target details. If all elements in a generated detail match the corresponding elements in the target detail, it counts as a correct item.\n",
        "  - **Compute Accuracy**: Divides the count of correct items by the total number of items to get the accuracy. Returns `0` if there are no items.\n",
        "\n",
        "### Execution\n",
        "\n",
        "- **`item_accuracy`**: Calls `compute_item_accuracy` with the `generated_details` and `target_details` to calculate the accuracy.\n",
        "- **Print Accuracy**: Prints the item-level accuracy with four decimal places.\n",
        "\n",
        "Item-level accuracy provides a metric of how well the model performs in predicting all categories correctly for each product.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnEiKsSEqL2U",
        "outputId": "b5615025-1996-4c16-e47c-bc7b4311701d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Item-level accuracy: 0.0350\n"
          ]
        }
      ],
      "source": [
        "def compute_item_accuracy(generated_details, target_details):\n",
        "    correct_items = 0\n",
        "    total_items = len(generated_details)\n",
        "\n",
        "    for gen, tar in zip(generated_details, target_details):\n",
        "        if all(g == t for g, t in zip(gen, tar)):\n",
        "            correct_items += 1\n",
        "\n",
        "    return correct_items / total_items if total_items > 0 else 0\n",
        "\n",
        "item_accuracy = compute_item_accuracy(generated_details, target_details)\n",
        "print(f\"Item-level accuracy: {item_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rRElc0xqL2V"
      },
      "source": [
        "## Saving Predictions to a File\n",
        "\n",
        "In this cell, we save the generated predictions to a file in JSONL format:\n",
        "\n",
        "- **`categories`**: List of categories for which predictions are made: `details_Brand`, `L0_category`, `L1_category`, `L2_category`, `L3_category`, and `L4_category`.\n",
        "\n",
        "- **`attrebute_test_baseline_200dp.predict`**: The output file where the predictions will be saved.\n",
        "\n",
        "### Process\n",
        "\n",
        "1. **Open File**: Opens the file `attrebute_test_baseline_200dp.predict` for writing.\n",
        "\n",
        "2. **Write Predictions**:\n",
        "   - **Iterate**: Loops through `generated_details` along with `indoml_id`, which acts as the identifier for each item.\n",
        "   - **Create Result**: Constructs a dictionary with `indoml_id` and the predicted values for each category.\n",
        "   - **Write to File**: Serializes the dictionary to JSON format and writes it to the file, one entry per line.\n",
        "\n",
        "This file can be used for evaluation or submission purposes, containing the model's predictions in the required format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj2wpmoGqL2V"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "categories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n",
        "\n",
        "with open('attrebute_test_baseline_200dp.predict', 'w') as file:\n",
        "\n",
        "    for indoml_id, details in enumerate(generated_details):\n",
        "        result = {\"indoml_id\": indoml_id}\n",
        "        for category, value in zip(categories, details):\n",
        "            result[category] = value\n",
        "\n",
        "        file.write(json.dumps(result) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY1XYgb5qL2V"
      },
      "source": [
        "## Creating a Zip Archive for Predictions\n",
        "\n",
        "In this cell, we create a zip archive of the predictions file:\n",
        "\n",
        "- **`file_to_zip`**: The name of the file containing the predictions (`attrebute_test_baseline_200dp.predict`).\n",
        "\n",
        "- **`zip_file_name`**: The name of the zip archive to be created (`any_name.zip`).\n",
        "\n",
        "### Process\n",
        "\n",
        "1. **Create Zip Archive**: Opens a new zip file (`any_name.zip`) for writing.\n",
        "\n",
        "2. **Add File to Zip**:\n",
        "   - **Add File**: Adds the predictions file (`attrebute_test_baseline_200dp.predict`) to the zip archive. The `arcname` parameter ensures that the file is stored in the zip archive with the same name as it has on the file system.\n",
        "\n",
        "The resulting zip file can be used for submission or sharing, compressing the predictions file into a standard format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-McMtJ9qL2V"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "\n",
        "# file_to_zip = 'attrebute_test_baseline_200dp.predict'\n",
        "# zip_file_name = 'any_name.zip'\n",
        "\n",
        "# with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
        "#     zipf.write(file_to_zip, arcname=file_to_zip)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d20fb058068849d6a25aa2337badb43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3324a40b085e4cd8803fd35939999ef7",
              "IPY_MODEL_c400590f1f2d4f1ab828ab5dd3ed004f",
              "IPY_MODEL_7ab9cae441494b4293d3c71b2c3202bb"
            ],
            "layout": "IPY_MODEL_2899c94ca5f84e448604274fc4d0a7c5"
          }
        },
        "3324a40b085e4cd8803fd35939999ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8148ca3e3343b3a03d412ab930bdf6",
            "placeholder": "​",
            "style": "IPY_MODEL_366a083d02bc49ef97cb531b8bdba882",
            "value": "Map: 100%"
          }
        },
        "c400590f1f2d4f1ab828ab5dd3ed004f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01974fd3572f4ec9923ea27a7237b75f",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc5b5b8e3de742b7b0b3fc81001d94c4",
            "value": 100000
          }
        },
        "7ab9cae441494b4293d3c71b2c3202bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959858984ddb4aa9a8ef78da46f9b62e",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed7f18df1944628982f8be53dd3aa5b",
            "value": " 100000/100000 [01:43&lt;00:00, 1592.11 examples/s]"
          }
        },
        "2899c94ca5f84e448604274fc4d0a7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8148ca3e3343b3a03d412ab930bdf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366a083d02bc49ef97cb531b8bdba882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01974fd3572f4ec9923ea27a7237b75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5b5b8e3de742b7b0b3fc81001d94c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "959858984ddb4aa9a8ef78da46f9b62e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed7f18df1944628982f8be53dd3aa5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93042bce986c4b33986037d5bfcbf2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b16e72491314f58a1ddb0a6de8e081b",
              "IPY_MODEL_282ccdbaef8148568d5b3622c0301f97",
              "IPY_MODEL_582df6e88d9b419ab7df84bf7a688d51"
            ],
            "layout": "IPY_MODEL_0a74f5be293f4281a0edb81e81b63e5c"
          }
        },
        "7b16e72491314f58a1ddb0a6de8e081b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8833f1db0a4352b43ac4a5fd9207b4",
            "placeholder": "​",
            "style": "IPY_MODEL_1a8a7fadd1e541c58098aee8fe15bbad",
            "value": "Map: 100%"
          }
        },
        "282ccdbaef8148568d5b3622c0301f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2773eedd07b4681960347e678592c4d",
            "max": 95036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d3da8fa096b4391aa85fa22e5471fed",
            "value": 95036
          }
        },
        "582df6e88d9b419ab7df84bf7a688d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df8095e49f24c4fbcf3a31e939ea6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_566b2801f17242fea1296dc10276bf81",
            "value": " 95036/95036 [00:39&lt;00:00, 1904.65 examples/s]"
          }
        },
        "0a74f5be293f4281a0edb81e81b63e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8833f1db0a4352b43ac4a5fd9207b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8a7fadd1e541c58098aee8fe15bbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2773eedd07b4681960347e678592c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3da8fa096b4391aa85fa22e5471fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df8095e49f24c4fbcf3a31e939ea6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566b2801f17242fea1296dc10276bf81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b2eafcf22124945898eaa754b75bb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54f585a7c3a244eb8555663a4019f899",
              "IPY_MODEL_30063e63df7348469dfc822fb47c2ce3",
              "IPY_MODEL_19b51daaad2c4a73b5005a970af4250e"
            ],
            "layout": "IPY_MODEL_1bfc2752a0304275a9322f80828b40c5"
          }
        },
        "54f585a7c3a244eb8555663a4019f899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a3177f63cb4ef380c2c36163dbb4cc",
            "placeholder": "​",
            "style": "IPY_MODEL_235a977084754a40ab761564cd2685b1",
            "value": "Map: 100%"
          }
        },
        "30063e63df7348469dfc822fb47c2ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d98d0124bf4d35bc42f62c07fdba02",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83b5096db9b94e1da2f73dbbd9a9d1ad",
            "value": 10000
          }
        },
        "19b51daaad2c4a73b5005a970af4250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d934ae5db84f808eeb38f521c9df99",
            "placeholder": "​",
            "style": "IPY_MODEL_82a9400ac7014b8b8a27cfc497849f6b",
            "value": " 10000/10000 [00:04&lt;00:00, 2470.73 examples/s]"
          }
        },
        "1bfc2752a0304275a9322f80828b40c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a3177f63cb4ef380c2c36163dbb4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235a977084754a40ab761564cd2685b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1d98d0124bf4d35bc42f62c07fdba02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b5096db9b94e1da2f73dbbd9a9d1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3d934ae5db84f808eeb38f521c9df99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a9400ac7014b8b8a27cfc497849f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}